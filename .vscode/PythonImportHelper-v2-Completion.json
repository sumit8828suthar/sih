[
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "APIRouter",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Depends",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "File",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "UploadFile",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "CORSMiddleware",
        "importPath": "fastapi.middleware.cors",
        "description": "fastapi.middleware.cors",
        "isExtraImport": true,
        "detail": "fastapi.middleware.cors",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "router",
        "importPath": "model_serve",
        "description": "model_serve",
        "isExtraImport": true,
        "detail": "model_serve",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "read_root",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def read_root():\n    return {\"Data\": \"Model Server v0.1\"}",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "app = FastAPI()\n# Add CORSMiddleware to allow requests from specified origins\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://localhost:3000\"],  # You can allow specific origins\n    allow_credentials=True,\n    allow_methods=[\"*\"],  # Allow all HTTP methods (GET, POST, etc.)\n    allow_headers=[\"*\"],  # Allow all headers\n)\napp.include_router(model_serve)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "serialize_index",
        "kind": 2,
        "importPath": "model_serve",
        "description": "model_serve",
        "peekOfCode": "def serialize_index(index): return list(index)\ndef predict(image_path, model, transform, device):\n    # Load and preprocess the image\n    image = Image.open(image_path)\n    if image.mode != 'RGB':\n        image = image.convert('RGB')  # Ensure 3 channels\n    input_tensor = transform(image).unsqueeze(0).to(device)\n    # Run inference\n    with torch.no_grad():\n        output = model(input_tensor)",
        "detail": "model_serve",
        "documentation": {}
    },
    {
        "label": "predict",
        "kind": 2,
        "importPath": "model_serve",
        "description": "model_serve",
        "peekOfCode": "def predict(image_path, model, transform, device):\n    # Load and preprocess the image\n    image = Image.open(image_path)\n    if image.mode != 'RGB':\n        image = image.convert('RGB')  # Ensure 3 channels\n    input_tensor = transform(image).unsqueeze(0).to(device)\n    # Run inference\n    with torch.no_grad():\n        output = model(input_tensor)\n        probabilities = torch.softmax(output, dim=1)",
        "detail": "model_serve",
        "documentation": {}
    },
    {
        "label": "router",
        "kind": 5,
        "importPath": "model_serve",
        "description": "model_serve",
        "peekOfCode": "router = APIRouter()\n@router.get(\"/getModelOutputs/\")\nasync def getModelOutputs(query_params: str,file: UploadFile = File(...)):\n    try:\n        # Define the path to your saved model\n        model_path = r\"resnet50_best_model.pth\"  # Update the path to match the actual structure\n        # Load the saved ResNet-50 model\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        num_classes = 3  # Update this to match your number of classes\n        model = models.resnet50()  # Initialize the ResNet-50 architecture",
        "detail": "model_serve",
        "documentation": {}
    }
]